{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import inv\n",
    "import cv2\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 이미지에 스티커 추가하기\n",
    "- 딥러닝 모델을 통한 얼굴 영역 검출 + dlib를 사용하여 얼굴 랜드마크 검출\n",
    "- 얼굴 좌표 에러 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2sticker(img_orig, img_sticker, landmark_predictor):\n",
    "    \n",
    "    (h, w) = img_orig.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(img_orig, (300, 300)), 1.0,\n",
    "    (300, 300), (104.0, 177.0, 123.0))\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    \n",
    "    rects = []\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence < 0.9:\n",
    "            continue\n",
    "\n",
    "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "        rect = dlib.rectangle(startX, startY, endX, endY)\n",
    "        rects.append(rect)\n",
    "\n",
    "    list_landmarks = []\n",
    "    for rect in rects:\n",
    "        points = landmark_predictor(img_orig, rect)\n",
    "        list_points = list(map(lambda p: (p.x, p.y), points.parts()))\n",
    "        list_landmarks.append(list_points)\n",
    "    \n",
    "    if not list_landmarks:\n",
    "        return img_orig\n",
    "\n",
    "    for rect, landmark in zip(rects, list_landmarks):\n",
    "        x = landmark[30][0] # nose\n",
    "        y = landmark[30][1] - rect.width()//2\n",
    "        w = rect.width()\n",
    "        h = rect.width()\n",
    "        print(x, y, w, h)\n",
    "        break\n",
    "    \n",
    "    # sticker\n",
    "    img_sticker = cv2.resize(img_sticker, (w,h), interpolation=cv2.INTER_NEAREST)\n",
    "    refined_x = x - w // 2\n",
    "    refined_y = y - h\n",
    "    \n",
    "    if refined_y < 0:\n",
    "        img_sticker = img_sticker[-refined_y:]\n",
    "        refined_y = 0\n",
    "    if refined_x < 0:\n",
    "        img_sticker = img_sticker[:, -refined_x:]\n",
    "        refined_x = 0\n",
    "    elif refined_x + img_sticker.shape[1] >= img_orig.shape[1]:\n",
    "        img_sticker = img_sticker[:, :-(img_sticker.shape[1]+refined_x-img_orig.shape[1])]\n",
    "\n",
    "    img_bgr = img_orig.copy()\n",
    "    sticker_area = img_bgr[refined_y:refined_y+img_sticker.shape[0], refined_x:refined_x+img_sticker.shape[1]]\n",
    "\n",
    "    img_bgr[refined_y:refined_y+img_sticker.shape[0], refined_x:refined_x+img_sticker.shape[1]] = \\\n",
    "        cv2.addWeighted(sticker_area, 1.0, img_sticker, 0.7, 0)\n",
    "\n",
    "    return img_bgr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 카메라 스트리밍을 통한 스티커앱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromCaffe(\"deploy.prototxt.txt\", \"res10_300x300_ssd_iter_140000.caffemodel\")\n",
    "landmark_predictor = dlib.shape_predictor('./models/shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "def main():\n",
    "    cv2.namedWindow('show', 0)\n",
    "    cv2.resizeWindow('show', 640, 360)\n",
    "\n",
    "    vc = cv2.VideoCapture(0)\n",
    "    img_sticker = cv2.imread('./images/king.png')\n",
    "\n",
    "    vlen = int(vc.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    while True:\n",
    "        ret, img = vc.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        start = cv2.getTickCount()\n",
    "        img = cv2.flip(img, 1)  # 보통 웹캠은 좌우 반전\n",
    "        \n",
    "        img_result = img2sticker(img, img_sticker.copy(), landmark_predictor)   \n",
    "\n",
    "        time = (cv2.getTickCount() - start) / cv2.getTickFrequency() * 1000\n",
    "        print ('[INFO] time: %.2fms'%time)\n",
    "        cv2.imshow('show', img_result)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 정리\n",
    "\n",
    "- 기존의 dlib 라이브러리를 사용하여 얼굴 검출을 할 시 이미지 피라미드 개수에 따라서 계산 속도의 차이가 컸으며, 다양한 거리에서의 얼굴을 검출하기 위해서는 계산 시간이 훨씬 오래걸렸습니다.\n",
    "\n",
    "- caffe 프레임워크로 개발된 resnet 모델을 사용하여, 기존에 dlib로 얼굴 영역 검출 부분을 대체시킴으로서 다양한 거리와 방향을 보는 얼굴들을 검출할 수 있게 되었으며 더 빠르게 검출해 낼 수가 있었습니다.\n",
    "\n",
    "- 얼굴이 좌측을 넘어 갈 때 x 좌표계 값이 음수가 되는 문제를 해결하여 기존의 스티커 앱에서 발생하던 오류를 제거 할 수있었습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
